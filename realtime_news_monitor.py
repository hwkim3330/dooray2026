#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ â†’ ì¤‘ìš” ë‰´ìŠ¤ ì¦‰ì‹œ ë‘ë ˆì´ ì•Œë¦¼
5ë¶„ë§ˆë‹¤ ì²´í¬, ìƒˆ ë‰´ìŠ¤ ë°œê²¬ì‹œ AI ë¶„ì„ í›„ ì•Œë¦¼
"""

import requests
import xml.etree.ElementTree as ET
import subprocess
import os
import json
import time
import urllib.parse
from datetime import datetime
from pathlib import Path

# ì„¤ì •
DOORAY_WEBHOOK = "https://keti.dooray.com/services/3711006199900720461/4145226571364668339/1QmQmcTCTMKf3FyF1OemZA"
CHECK_INTERVAL = 1800  # 30ë¶„
SEEN_FILE = Path("/home/kim/dooray-claude-bot/logs/seen_news.json")

# ë‰´ìŠ¤ ì†ŒìŠ¤
NEWS_SOURCES = {
    "GeekNews": "https://news.hada.io/rss/news",
}

# ì£¼ì‹ ê´€ë ¨ í‚¤ì›Œë“œ (ì¤‘ìš”í•œ ê²ƒë§Œ)
STOCK_KEYWORDS = [
    "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "ì—”ë¹„ë””ì•„", "í…ŒìŠ¬ë¼",
    "ê¸ˆë¦¬ì¸ìƒ", "ê¸ˆë¦¬ì¸í•˜", "ì—°ì¤€", "FOMC",
    "IPO", "ìƒì¥íì§€", "ì¸ìˆ˜í•©ë³‘",
    "ì‹¤ì ë°œí‘œ", "ì–´ë‹ì„œí”„ë¼ì´ì¦ˆ",
    "íŠ¸ëŸ¼í”„", "ê´€ì„¸",
]

# ê¸´ê¸‰ í‚¤ì›Œë“œ (ë°”ë¡œ ì•Œë¦¼)
URGENT_KEYWORDS = [
    "ì†ë³´", "ê¸´ê¸‰", "í­ë½", "í­ë“±", "ê¸‰ë“±", "ê¸‰ë½", "ì„œí‚·ë¸Œë ˆì´ì»¤",
]

def load_seen():
    """ì´ë¯¸ ë³¸ ë‰´ìŠ¤ ID ë¡œë“œ"""
    if SEEN_FILE.exists():
        return set(json.loads(SEEN_FILE.read_text()))
    return set()

def save_seen(seen):
    """ë³¸ ë‰´ìŠ¤ ID ì €ì¥"""
    SEEN_FILE.parent.mkdir(parents=True, exist_ok=True)
    SEEN_FILE.write_text(json.dumps(list(seen)[-500:]))  # ìµœê·¼ 500ê°œë§Œ

def fetch_news():
    """ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    all_news = []

    for source, url in NEWS_SOURCES.items():
        try:
            resp = requests.get(url, timeout=30)
            root = ET.fromstring(resp.content)
            ns = {'atom': 'http://www.w3.org/2005/Atom'}

            for entry in root.findall('atom:entry', ns)[:10]:
                news_id = entry.find('atom:id', ns)
                title = entry.find('atom:title', ns)
                link = entry.find('atom:link', ns)
                content = entry.find('atom:content', ns)

                if news_id is not None and title is not None:
                    all_news.append({
                        'id': news_id.text,
                        'source': source,
                        'title': title.text,
                        'link': link.get('href') if link is not None else '',
                        'content': content.text[:500] if content is not None and content.text else '',
                    })
        except Exception as e:
            print(f"[{source}] ì˜¤ë¥˜: {e}")

    return all_news

def is_stock_related(title, content):
    """ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ì¸ì§€ í™•ì¸"""
    text = title + " " + content

    # ê¸´ê¸‰ í‚¤ì›Œë“œ ë¨¼ì € ì²´í¬
    for keyword in URGENT_KEYWORDS:
        if keyword in text:
            return True, f"ğŸš¨{keyword}"

    # ì¼ë°˜ í‚¤ì›Œë“œ
    for keyword in STOCK_KEYWORDS:
        if keyword in text:
            return True, keyword

    return False, None

def analyze_importance(news_item):
    """AIë¡œ ë‰´ìŠ¤ ì¤‘ìš”ë„ ë¶„ì„"""
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ê°€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì— ë¯¸ì¹  ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì œëª©: {news_item['title']}
ë‚´ìš©: {news_item['content'][:300]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€:
ì¤‘ìš”ë„: (ìƒ/ì¤‘/í•˜)
ì˜í–¥: (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
ê´€ë ¨ì„¹í„°: (ì„¹í„°ëª…)
ê´€ë ¨ì¢…ëª©: (í•œêµ­ ìƒì¥ ì¢…ëª© 1-2ê°œ)
í•œì¤„ìš”ì•½: (íˆ¬ììê°€ ì•Œì•„ì•¼ í•  í•µì‹¬)

ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”."""

    try:
        # ë¡œì»¬ Claude (ë¹ ë¦„)
        result = subprocess.run(
            ["claude", "-p", prompt, "--model", "haiku"],
            capture_output=True,
            text=True,
            timeout=30,
            env={**os.environ, "LANG": "ko_KR.UTF-8"}
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except:
        pass

    return None

def send_alert(news_item, analysis, keyword):
    """ë‘ë ˆì´ë¡œ ì•Œë¦¼"""
    now = datetime.now().strftime("%H:%M")

    message = f"""ğŸš¨ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì•Œë¦¼ [{now}]

ğŸ“° {news_item['title']}

ğŸ”‘ í‚¤ì›Œë“œ: {keyword}
ğŸ“ ì¶œì²˜: {news_item['source']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{analysis if analysis else '(ë¶„ì„ ì¤‘...)'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”— {news_item['link']}

âš ï¸ íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤.
"""

    payload = {
        "botName": "ë‰´ìŠ¤ì•Œë¦¼",
        "botIconImage": "https://em-content.zobj.net/source/apple/391/bell_1f514.png",
        "text": message
    }

    try:
        resp = requests.post(DOORAY_WEBHOOK, json=payload, timeout=10)
        return resp.status_code == 200
    except:
        return False

def main():
    print(f"[{datetime.now()}] ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„° ì‹œì‘")
    print(f"ì²´í¬ ê°„ê²©: {CHECK_INTERVAL}ì´ˆ")
    print(f"í‚¤ì›Œë“œ: {len(STOCK_KEYWORDS)}ê°œ")
    print("-" * 50)

    seen = load_seen()

    while True:
        try:
            news_list = fetch_news()
            new_count = 0

            for news in news_list:
                if news['id'] in seen:
                    continue

                # ìƒˆ ë‰´ìŠ¤ ë°œê²¬
                seen.add(news['id'])

                # ì£¼ì‹ ê´€ë ¨ ì²´í¬
                is_related, keyword = is_stock_related(news['title'], news['content'])

                if is_related:
                    print(f"[ìƒˆ ë‰´ìŠ¤] {news['title'][:50]}... (í‚¤ì›Œë“œ: {keyword})")

                    # AI ë¶„ì„
                    analysis = analyze_importance(news)

                    # ì•Œë¦¼ ì „ì†¡
                    if send_alert(news, analysis, keyword):
                        print(f"  â†’ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
                        new_count += 1
                    else:
                        print(f"  â†’ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")

            save_seen(seen)

            if new_count == 0:
                print(f"[{datetime.now().strftime('%H:%M')}] ìƒˆ ë‰´ìŠ¤ ì—†ìŒ")

        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")

        time.sleep(CHECK_INTERVAL)

if __name__ == "__main__":
    main()
